# ğŸ”„ kafka-event-pipeline

## ğŸ§° Producteur/Consommateur Kafka avec Spring Boot + Monitoring Kafdrop

### â— ProblÃ¨me Ã  rÃ©soudre :  
### **"ğŸ“¬ Publier des Ã©vÃ©nements via une API REST â†’ Kafka â†’ Consommateur â†’ Stockage en base PostgreSQL"**

---
### ğŸ”ğŸŒ Fonctionnement
Ce projet simule une chaÃ®ne dâ€™Ã©vÃ©nements complÃ¨te :

1. Postman envoie un `POST /api/events`
2. Le Producteur Spring Boot publie lâ€™Ã©vÃ©nement sur un topic Kafka
3. Le Cluster Kafka rÃ©plique le message sur 3 brokers
4. Le Consommateur Spring Boot lit et sauvegarde les Ã©vÃ©nements dans PostgreSQL
5. Kafdrop permet dâ€™inspecter les messages en temps rÃ©el

---

### ğŸ§¾ FonctionnalitÃ©s principales

- âš–ï¸ RÃ©partition automatique des partitions sur 3 brokers Kafka
- ğŸ“® API REST pour publier les Ã©vÃ©nements
- ğŸ‘‚ Consumer qui Ã©coute le topic `events-topic`
- ğŸ’¾ Persistance des messages dans PostgreSQL
- ğŸ§­ Kafdrop UI pour visualiser les topics et partitions Kafka
- ğŸ³ Infrastructure complÃ¨te via `docker-compose`

---

### ğŸ› ï¸ Stack technique

| Composant | Description |
|-----------|-------------|
| <img src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/spring/spring-original.svg" width="24"/> Spring Boot | Producteur & Consommateur Kafka |
| <img src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/postgresql/postgresql-original.svg" width="24"/> PostgreSQL | Base de donnÃ©es pour le stockage des Ã©vÃ©nements |
| <img src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/docker/docker-original.svg" width="24"/> Docker Compose | DÃ©ploiement multi-conteneurs |
| <img src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/apachekafka/apachekafka-original-wordmark.svg" width="24"/> Apache Kafka | Broker de messages Kafka |
| <img src="https://raw.githubusercontent.com/obsidiandynamics/kafdrop/master/src/main/resources/static/images/kafdrop-logo.png" width="24"/> Kafdrop | Interface web pour surveiller Kafka |


---

## ğŸ›¢ï¸ Structure de la base de donnÃ©es

| id | uuid | timestamp |

---

## ğŸ“Š Diagramme de flux



```mermaid
flowchart TD
  subgraph DockerCompose

    subgraph Producteur
      A[Postman] -->|POST /api/events| B[Spring Boot - Producer]
    end

    subgraph Cluster Kafka
      B -->|send message| C[Kafka Topic: events-topic]
    end

    subgraph KafkaCluster
      C --> P1[Partition 1 - Broker 1]
      C --> P2[Partition 2 - Broker 2]
      C --> P3[Partition 3 - Broker 3]
    end

    subgraph Monitoring
      K[Kafdrop UI] --> C
    end

    subgraph Consommateur
      D[Spring Boot - Consumer] -->|consume| C
      D -->|persist| DB[(PostgreSQL DB)]
    end

  end




